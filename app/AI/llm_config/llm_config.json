{
    "providers": {
        "azure": {
            "base_url": "https://models.inference.ai.azure.com",
            "model": "gpt-4o",
            "embedding_model": null,
            "provider": "azure",
            "temperature": 0.7,
            "max_tokens": 150,
            "top_p": 1,
            "frequency_penalty": 0,
            "presence_penalty": 0,
            "stop": null,
            "stream": true,
            "stream_options": {
                "include_usage": true
            }
        },
        "groq": {
            "base_url": "https://api.groq.com/openai/v1/chat/completions",
            "model": "meta-llama/llama-4-scout-17b-16e-instruct",
            "embedding_model": null,
            "provider": "groq",
            "temperature": 0.7,
            "max_tokens": 1024,
            "top_p": 1,
            "stream": true,
            "stop": null
        },
        "gemini": {
            "base_url": "https://generativelanguage.googleapis.com/v1beta/models",
            "model": "gemini-2.0-flash",
            "embedding_model": "embedding-001",
            "provider": "gemini",
            "temperature": 0.7,
            "max_tokens": 1048576,
            "top_p": 1,
            "stream": true,
            "stop": null
        }
    },
    "default_provider": "gemini",
    "cache": {
        "enabled": true,
        "cache_size": 100,
        "cache_expiry": 3600
    }
}