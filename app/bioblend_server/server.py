import os
from fastmcp import FastMCP
import logging
from typing import Any, Optional
import redis
import asyncio
import json
import httpx
from contextlib import asynccontextmanager

from bioblend.galaxy.client import ConnectionError as GalaxyConnectionError
from qdrant_client.models import PointStruct
from qdrant_client.http.exceptions import ApiException

from app.log_setup import configure_logging
from app.bioblend_server.utils import JWTGalaxyKeyMiddleware, current_api_key_server, get_llm_response
from app.galaxy import GalaxyClient

from app.bioblend_server.background_runner import BackgroundIndexer
from app.bioblend_server.informer.informer import GalaxyInformer

from app.enumerations import InvocationStates

from app.orchestration.invocation_cache import InvocationCache
from app.orchestration.invocation_tasks import InvocationBackgroundTasks

from app.persistence import MongoStore
from app.GX_integration.invocations.invocation_service import InvocationService
from app.GX_integration.workflows.workflow_manager import WorkflowManager
from app.GX_integration.invocations.data_manager import InvocationDataManager

configure_logging()
logger = logging.getLogger("fastmcp_bioblend_server")

mongo_client = MongoStore()
redis_client = redis.Redis(host=os.getenv("REDIS_HOST", "localhost"), port=os.getenv("REDIS_PORT"), db=0, decode_responses=True)
invocation_cache = InvocationCache(redis_client)
invocation_background = InvocationBackgroundTasks(cache = invocation_cache, redis_client = redis_client)
invocation_service = InvocationService(cache = invocation_cache, background_tasks= invocation_background, mongo_client= mongo_client)
inv_data_manager = InvocationDataManager(cache = invocation_cache, background_tasks = invocation_background)

if not os.environ.get("GALAXY_API_KEY") or not os.environ.get("QDRANT_HTTP_PORT") or not os.environ.get("CURRENT_LLM"):
    logger.warning("MCP server environment variables are not set.")

@asynccontextmanager
async def mcp_galaxy_lifespan(server: FastMCP):
    """ 
    Manages the lifecycle of the background indexer.
    Ensures it starts with the server and shuts down gracefully.
    """
    # 1. Initialize the worker and start loop
    indexer = BackgroundIndexer()
    loop_task = asyncio.create_task(indexer.run_loop())
    
    yield 
    
    # 3. Graceful Shutdown
    logger.info("Server shutting down, stopping background tasks...")
    loop_task.cancel()
    try:
        # Wait for the task to acknowledge cancellation
        await loop_task
    except asyncio.CancelledError:
        pass
    logger.info("Background tasks stopped cleanly.")
    
    
# ==================================== #
     ## Main FastMCP Server ##
# ==================================== #

bioblend_app = FastMCP(
                        name="galaxyTools",
                        instructions="""
                                    You have tools for interacting with a Galaxy instance.
                                    These tools support these distinct capabilities:
                                    
                                    (1) (**get_galaxy_information_tool**) Querying **Galaxy information** to retrieve **accurate and upto date details(information)** about available tools, datasets, or workflows in **Galaxy**. 
                                        Used for tool/workflow recommendations, To respond accurately when asked about the available tools, datasets, or workflows in the galaxy instance.
                                        used only for gathering information to **respond to galaxy related queries**.
                                        
                                    (2) (**execute_galaxy_tool_workflow**) Executing Galaxy operations to run a specific tool or execute a workflow (used only when the user explicitly requests this operation).
                                    
                                    Always keep querying and executing strictly separate in purpose and usage.
                                    """,
                        middleware=[JWTGalaxyKeyMiddleware()],
                        lifespan=mcp_galaxy_lifespan
                    )

@bioblend_app.tool()
async def get_galaxy_information_tool(
    query: str,
    query_type: str,
    entity_id: str = None
) -> str:
    """
    Fetch detailed information on Galaxy tools, workflows, datasets, and invocations.

    This tool handles all information requests about Galaxy entities, based on
    the `query_type` (tool, workflow, dataset) and the user's `query`.
    Use `entity_id` only when the user's query explicitly includes an ID.

    Args:
        query: The user's query message that needs a response, accompanied by full and detailed contextual information.
        query_type: The type of Galaxy entity the query needs a response for, with one of three values: "tool", "dataset", or "workflow".
                    Select "workflow" for general workflow details and specific workflow invocation details.
        entity_id: Optional parameter. Provide this only when the user's query explicitly includes an ID,
                   allowing retrieval of information by that specific entity ID.

    Returns:
        A string containing the detailed Galaxy information and the response to the user's query.
    """
    logger.info(f"Calling get_galaxy_information with query='{query}', query_type='{query_type}', entity_id='{entity_id}'")
    try:
        # Get current user
        user_api_key = current_api_key_server.get()
        if user_api_key is None:
            raise ValueError("current user api-key is missing")        

        # Create galaxy instances
        galaxy_client = GalaxyClient(user_api_key)
        logger.info( f"current Galaxy MCP server user: {galaxy_client.whoami}")
        # Create GalaxyInformer object and execute informer
        informer = await GalaxyInformer.create(galaxy_client=galaxy_client, entity_type=query_type)
        result = await informer.get_entity_info(search_query = query, entity_id = entity_id)
        return result
    
    except GalaxyConnectionError as e:
        logger.error(f"Failed to connect to Galaxy: {e}")
        return f"Failed to connect to Galaxy: {e}"
    except Exception as e:
        logger.error(f"Error in get_galaxy_information_tool: {e}", exc_info=True)
        return f"An error occurred while fetching Galaxy information: {str(e)}"
    

@bioblend_app.tool()
async def explain_galaxy_workflow_invocation(
    invocation_id: str,
    failure: bool
) -> str:
    """
    Generates a detailed explanation of a Galaxy workflow invocation.

    This function retrieves and analyzes metadata for a given Galaxy workflow invocation.
    It either summarizes successful outputs or provides diagnostic details for failed jobs,
    and suggest fixes for workflow invocation.

    Args:
        invocation_id (str): 
            The unique identifier of the Galaxy workflow invocation to analyze.
        failure (bool): 
            Indicates whether to focus on failed job diagnostics (`True`) or 
            output dataset summaries (`False`), if empty it defaults to false.

    Returns:
        str: A clear report of the workflow invocation results or a report explaining failure causes with actionable suggestions.
    """
    
    # Get current user
    user_api_key = current_api_key_server.get()
    if user_api_key is None:
        raise ValueError("current user api-key is missing")
    
    try:
        
        invocation_analysis: str = await analyze_invocation(invocation_id = invocation_id, user_api_key = user_api_key, failure=failure)
        
        if failure:
            logger.info("Loading failure explanation and suggestions for invocation.")
            invocation_prompt = f"""
                You are a Galaxy workflow expert.

                Analyze the following workflow invocation report.
                Identify why the workflow failed and suggest clear, actionable fixes.

                Report:
                {invocation_analysis}

                Respond with:
                - Root cause of failure(s)
                - Recommended fix or next step
                """
        else:
            logger.info("Loading summarized report for successful invocation.")
            invocation_prompt = f"""
                You are a Galaxy workflow expert.

                Summarize this successful workflow invocation report.

                Report:
                {invocation_analysis}

                Respond with:
                - What the workflow accomplished
                - Key output datasets or collections
                - Next logical steps for the user
                """
        try:
            response = await get_llm_response(message = invocation_prompt)
        except Exception as e:
            logger.error(f"Error preparing structured suggestions, returning full report. {e}")
            response = invocation_analysis
        return response
    
    except GalaxyConnectionError as e:
        logger.error(f"Failed to connect to Galaxy: {e}")
        return f"Failed to connect to Galaxy: {e}"
    except Exception as e:
        logger.error(f"Error caused whn trying to fetch invocation details: {e}")
        return f"Error caused whn trying to fetch invocation details: {e}"
        

async def fetch_workflow_json_async(url: str) -> dict[str, Any]:
            """Fetch and load JSON from a given URL using httpx (async)."""
            
            async with httpx.AsyncClient(timeout=30.0) as http_client:
                response = await http_client.get(url)
                response.raise_for_status()
                return json.loads(response.text)
            

# TODO: Import workflow from the IWC by its name, for now lets use the url for dev, but improve the workflow
@bioblend_app.tool()
async def import_workflow_to_galaxy_instance(
    workflow_name: str
) -> str:
    # TODO: No Galaxy duplicate check add that.
    
    """
    Imports a Galaxy workflow from the IWC workflow repository, fetching the workflow JSON,
    and uploading it to the Galaxy instance. Handles tool installation and ensures the workflow is added to the user's list.

    Args:
        workflow_name (str): The Full and exact name of the workflow to import.

    Returns:
        str: A message indicating the import status or an error description.
    """
    try:
        
        from app.bioblend_server.informer.manager import InformerManager
        
        # Validate API key and initialize clients
        user_api_key: str = current_api_key_server.get()
        if not user_api_key:
            raise ValueError("User API key is not provided.")
        
        galaxy_client: GalaxyClient = GalaxyClient(user_api_key)
        username = galaxy_client.whoami
        workflow_manager: WorkflowManager = WorkflowManager(galaxy_client)
        qdrant_client: InformerManager = await InformerManager().create()

        # TODO: Fill the workflow collection name (has to be user-specific, so ...)
        workflow_collection_name: str = "generic_galaxy_workflow"

        # Step 1: Search for the workflow by name in metadata (synchronous call in thread pool)
        logger.info(f"Searching for workflow '{workflow_name}' in collection '{workflow_collection_name}'.")
        logger.info(f"current Galaxy MCP server user: {username}")
        hits = await qdrant_client.match_name_from_collection(
            workflow_collection_name=workflow_collection_name,
            workflow_name = workflow_name
            )

        if not hits or not hits[0]:
            logger.warning(f"Workflow '{workflow_name}' not found in collection '{workflow_collection_name}'")
            return f"Workflow '{workflow_name}' not found in available workflow collection for import."

        # Extract workflow download URL from point payload
        point: PointStruct = hits[0][0]
        workflow_url: Optional[str] = point.payload.get("raw_download_url")
        
        if not workflow_url:
            logger.error(f"No download link found for workflow '{workflow_name}'")
            return f"Couldn't import workflow '{workflow_name}'."

        # Fetch the workflow JSON
        logger.info(f"Fetching workflow JSON from IWC repository using URL: {workflow_url}")
        workflow_json: dict = await fetch_workflow_json_async(workflow_url)

        # TODO: Ensure that getting the workflow name is correct.
        ga_workflow_name: str = workflow_json.get("name", workflow_json.get("workflow_name", ""))
        if not ga_workflow_name:
            logger.error(f"Workflow JSON does not contain a 'name' field for '{workflow_name}'")
            raise ValueError(f"Workflow JSON does not contain a 'name' field for '{workflow_name}'.")

        # Background upload task
        logger.info(f"Initiating upload of workflow '{ga_workflow_name}'")
        
        asyncio.create_task(
            workflow_manager.upload_workflow(
                workflow_json=workflow_json
                )
            )

        return f"{ga_workflow_name} workflow is being imported, mssing tools are being checked and installed, and the workflow will be added to your workflow list shortly."
    
    except GalaxyConnectionError as e:
        logger.error(f"Failed to connect to Galaxy: {e}")
        return f"Failed to connect to Galaxy: {e}"
    except httpx.HTTPStatusError as http_err:
        logger.error(f"HTTP error fetching workflow from IWC repository: {str(http_err)}")
        return f"HTTP error occurred while fetching workflow from IWC repository: {str(http_err)}"
    except httpx.RequestError as req_err:
        logger.error(f"Network error fetching workflow from IWC repository: {str(req_err)}")
        return f"Request HTTP error occurred while fetching workflow from IWC repository: {str(req_err)}"
    except ApiException as qdrant_err:
        logger.error(f"Qdrant error during workflow search: {str(qdrant_err)}")
        return f"Qdrant error occurred during workflow search: {str(qdrant_err)}"
    except ValueError as val_err:
        logger.error(f"Validation error: {str(val_err)}")
        return f"Value error: {str(val_err)}"
    except Exception as exc:
        logger.exception(f"Unexpected error during workflow import: {str(exc)}")
        return f"An unexpected error occurred during workflow import: {str(exc)}"
    
    
async def analyze_invocation(invocation_id: str, user_api_key: str, failure: bool) -> str:
    # instantiate galaxy client and invocation cacher classes
    galaxy_client = GalaxyClient(user_api_key)
    username = galaxy_client.whoami
    
    logger.info(f"Loading workflow Invocation with ID: {invocation_id} for explanationn for current Galaxy MCP server user: {username}")
    
    # Retrieve invocation details and workflow title concurrently
    try:
        def get_invocation_details():
            return galaxy_client.gi_client.invocations.show_invocation(invocation_id)
        
        def get_invocation_report():
            return galaxy_client.gi_client.invocations.get_invocation_report(invocation_id)
        
        invocation_details, invocation_report = await asyncio.gather(
            asyncio.to_thread(get_invocation_details),
            asyncio.to_thread(get_invocation_report)
        )
    except Exception as e:
        logger.error(f"Error retrieving invocation details or report: {str(e)}")
        return f"Error retrieving invocation details or report for ID {invocation_id}: {str(e)}"
    
    # Retrieve workflow details using the invocation report
    workflow_name = invocation_report.get("title", "Unknown")
    
    # Initialize explanation string
    explanation = "\n\n**Invocation details**"
    explanation += f"\n\nWorkflow Invocation ID: {invocation_id}\nWorkflow Name: {workflow_name}\n"
    
    # Check invocation state
    invocation_state = await invocation_cache.get_invocation_state(username, invocation_id)
    if invocation_state is None:
        invocation_raw_state = invocation_details.get('state', "Unknown")
    
        if invocation_raw_state == "scheduled":
            invocation_state = InvocationStates.PENDING.value
            
            try:
                workflow_manager = WorkflowManager(galaxy_client=galaxy_client)

                asyncio.create_task(
                    invocation_service.get_invocation_result(
                        invocation_id = invocation_id,
                        username=username,
                        api_key = current_api_key_server,
                        galaxy_client=galaxy_client,
                        workflow_manager= workflow_manager,
                        ws_manager=None
                        )
                    )
                explanation += "Workflow invocation still in Pending state. tracking workflow invocation."
            except Exception as e:
                logger.error(f"Error retrieving or tracking scheduled invocation: {str(e)}")
                explanation += f"\nError tracking scheduled invocation: {str(e)}\n"
        else:
            invocation_state = InvocationStates.FAILED.value
    
    invocation_inputs: dict = invocation_details.get("inputs", {})
    invocation_input_parameters: dict = invocation_details.get("input_step_parameters", {})
    if invocation_inputs:
        explanation += "\n\nInvocation input datasets:\n"
        explanation += "\n".join(f"  - {label.get('label')}" for label in invocation_inputs.values()) + "\n"

    if invocation_input_parameters:
        explanation += "\n\nInvocation input parameters:\n"
        explanation += "\n".join(f"  - {label.get('label')}: {label.get('parameter_value')}" for label in invocation_input_parameters.values()) + "\n"
    
    explanation += f"\n\nInvocation State: {invocation_state}\n\n"
    
    # If failure is indicated, focus on errors; otherwise, report on outputs
    if failure or invocation_state not in [InvocationStates.PENDING.value, InvocationStates.COMPLETE.value]:
        
        failure = True
        explanation += "Analysis for failures in the workflow invocation:\n"
        
        # Get failure reports or the invocation.
        explanation += await inv_data_manager.report_invocation_failure(galaxy_client, invocation_id)
        
        return explanation
    if invocation_state == "pending":
        explanation += "\n\nInvocation still Pending but no indicated failure. Analyzing output datasets:\n"
    else:
        explanation += "\n\nInvocation completed without indicated failure. Analyzing output datasets:\n"
        
    invocation_outputs = invocation_details.get('outputs', {})
    invocation_output_collections = invocation_details.get("output_collections", {})
    
    if invocation_outputs:
        explanation += "\n\nInvocation output datasets:\n"
        explanation += "\n".join(f"  - {label}" for label in invocation_outputs.keys()) + "\n"
    
    if invocation_output_collections:
        explanation += "\n\nInvocation output dataset collections:\n"
        explanation += "\n".join(f"  - {label}" for label in invocation_output_collections.keys()) + "\n" 
        
    if not invocation_outputs and not invocation_output_collections:
        explanation += "\nNo output datasets or collections found for this invocation.\n"
    
    return explanation